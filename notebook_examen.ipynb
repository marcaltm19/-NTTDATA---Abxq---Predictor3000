{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e227a4fb",
   "metadata": {},
   "source": [
    "### Treure info de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborm as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.head()\n",
    "table.shape\n",
    "table.describe()\n",
    "table.info() # √∫til x saber total de nulls\n",
    "table.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d44a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.boxplot()\n",
    "sns.pairplot(table, kind=\"reg\", hue=\"name_column\")\n",
    "heatmap = sns.heatmap(table.corr(), annot=True, linewidths=0, vmin=-1, cmap=\"RdBu_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in new_df.columns:\n",
    "    plt.figure()\n",
    "    sns.histplot(data=new_df, x=column, hue=\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1):\n",
    "    X.hist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c409ceb",
   "metadata": {},
   "source": [
    "### Dividir dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ad789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "matriu_x= table.iloc[:, :-1]\n",
    "matriu_y= table.iloc[:, -1]\n",
    "edu.loc[:, \"y_column\":\"y_column\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(matriu_x, \n",
    "                                                    matriu_y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1,5,10]\n",
    "quality_labels=[0,1]\n",
    "dataset['quality_categorical'] = pd.cut(dataset['quality'], bins=bins, labels=quality_labels, include_lowest=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "478dc869",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_fillna(data,option=0):\n",
    "    \n",
    "    data = clean_data(data)\n",
    "    #TODO\n",
    "    # OPCIO 0: Elimines les files on hi ha \"nan\"\n",
    "    # OPCIO 1: Canvies els Nan per la mitjana de la columna corresponent\n",
    "    # OPCIO 2: Canvies Pel maxim\n",
    "    # OPCIO 3: Canvies el nan per un nombre aleatori per un valor dintre de la distribuci√≥ de les dades de la columna que no s√≥n nan\n",
    "    df = data.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "    if option == 0:\n",
    "        return df.dropna()\n",
    "    \n",
    "    if option == 1:\n",
    "        df = df.fillna(method=\"ffill\")\n",
    "        dg = df.fillna(df.mean())\n",
    "\n",
    "        return dg\n",
    "\n",
    "    if option == 2:\n",
    "        max_values = df.max(axis=0).values\n",
    "        with_max = df.fillna(dict(zip(df.columns,max_values)))\n",
    "        \n",
    "        return with_max\n",
    "    \n",
    "    if option == 3:\n",
    "        \n",
    "        means = df.mean().values\n",
    "        stds = df.std().values\n",
    "\n",
    "        df_copy = pd.DataFrame().reindex_like(df).select_dtypes(exclude=[\"object\"])\n",
    "        \n",
    "        for idx, column in enumerate(df_copy):\n",
    "            df_copy[column] = abs(np.random.normal(means[idx], stds[idx], df_copy.shape[0]))\n",
    "                    \n",
    "        return df_copy.where(df.isnull(), df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17eec908",
   "metadata": {},
   "source": [
    "### Normalitzacions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b8ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, SantardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "\n",
    "normalizer = Normalizer()\n",
    "scaler = normalizer.fit(x_train)\n",
    "normalized_x_train= scaler.transform(x_train)\n",
    "scaler.fit_transform(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ab4b812",
   "metadata": {},
   "source": [
    "### Codificaci√≥ atributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccada6ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16708\\1178234510.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOrdinalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'buying'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mencoded_X_train_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mencoded_X_test_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Una manenra d'aplicar-ho a columnes en concret\n",
    "import category_encoders as ce\n",
    "\n",
    "# encoder = ce.OrdinalEncoder(cols=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n",
    "encoder = ce.OrdinalEncoder(cols=['buying'])\n",
    "\n",
    "encoded_X_train_1 = encoder.fit_transform(X_train)\n",
    "encoded_X_test_1 = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd94587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "encoders = defaultdict(LabelEncoder)\n",
    "\n",
    "# Encoding the variable\n",
    "encoded_X_train_2 = X_train.apply(lambda x: encoders[x.name].fit_transform(x))\n",
    "encoded_X_test_2 = X_test.apply(lambda x: encoders[x.name].transform(x))\n",
    "\n",
    "# Inverse the encoded\n",
    "inversed_X_train = encoded_X_train_2.apply(lambda x: encoders[x.name].inverse_transform(x))\n",
    "\n",
    "# Using the dictionary to label future data\n",
    "# X_train.apply(lambda x: encoders[x.name].transform(x))\n",
    "\n",
    "print(\"\\n The result of transforming X with LabelEncoder:\")\n",
    "print(encoded_X_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cede7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder --> bo quan els atributs presenten ordinalitat. Preferiblement usar en el target que en l'input\n",
    "# OrdinalEncoder --> la assignaci√≥ la fa en l'ordre en que troba les dades\n",
    "# OneHot --> crea tants nous atributs per cada antic com possibilitats d'aquest hi ha. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7aa347e8",
   "metadata": {},
   "source": [
    "### Regressors i funcions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dab068c5",
   "metadata": {},
   "source": [
    "#### Linear regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a75018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "rgr = linear_model.SGDRegressor()  # regressors lineals\n",
    "rgr = linar_model.LinearRegression() # normal equation\n",
    "\n",
    "\n",
    "rgr.fit(X_train, y_train)\n",
    "rgr.predict(X_test)\n",
    "rgr.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree)\n",
    "poly.fit(X_train)\n",
    "X_poly = poly.transform(X)\n",
    "model.fit(X_poly, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5eefb2d",
   "metadata": {},
   "source": [
    "#### Logistic regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8278d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier() # classificador (regressor log√≠stic (loss=\"log_loss\", svm (default))\n",
    "lr = linear_model.LogisticRegression() # classificador amb regressor log√≠stic\n",
    "\n",
    "\n",
    "clf.predict_proba(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10230e41",
   "metadata": {},
   "source": [
    "#### Logistic regressor multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression()\n",
    "ovr = OneVsRestClassifier(model)\n",
    "#L'OVR va be quan tens casos una mica m√©s desbalancejats per a nivellar el aprenentatge \n",
    "#de les classes.\n",
    "ovo = OneVsOneClassifier(model)\n",
    "#El OVO √©s una bona estrat√®gia quan tens unes dades molt balancejades i sobre tot va molt be quan en tens moltes, \n",
    "#donat que estas entrenant models molt m√©s petits.\n",
    "\n",
    "ovr.fit(X, y)\n",
    "ovr.decision_function(X_test)\n",
    "ovr.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37365271",
   "metadata": {},
   "source": [
    "#### svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e48371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear', C=1E0)\n",
    "clf = SVC(kernel='rbf')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_train_scr = clf.decision_function(X_train)\n",
    "\n",
    "clf.support_vectors_ \n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), LinearSVC(max_iter=10000))\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.coef_ i clf.intercept_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b450b777",
   "metadata": {},
   "source": [
    "#### decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d336b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1234)\n",
    "clf.fit(encoded_X_train_2, y_train)\n",
    "text_representation = tree.export_text(clf)\n",
    "print(text_representation)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a5b00f6",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050df5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(encoded_X_train_2, y_train)\n",
    "clf.predict(encoded_X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab900937",
   "metadata": {},
   "source": [
    "#### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, CategoricalNB\n",
    "\n",
    "def experiment(dataset_name, model, debug=True):\n",
    "    X, y = load_dataset(dataset_name)\n",
    "    model.fit(X, y.values.ravel())\n",
    "    score = model.score(X, y.values.ravel())\n",
    "    return score\n",
    "\n",
    "models = {\"GaussianNB\": GaussianNB(), \"MultinomialNB\": MultinomialNB(), \"BernoulliNB\": BernoulliNB(), \"CategoricalNB\": CategoricalNB()}\n",
    "di = {}\n",
    "for model_name, model in models.items():\n",
    "    result = experiment(model)\n",
    "    di[model_name] = result\n",
    "    print(result)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(di.keys(), di.values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cdf67ae",
   "metadata": {},
   "source": [
    "### Avaluadors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c752fce6",
   "metadata": {},
   "source": [
    "#### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e19a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score,\n",
    "mean_squared_error, r2_score\n",
    "\n",
    "error = mean_squared_error(y_test,predict)\n",
    "r2_score(y_test,predict)\n",
    "\n",
    "recall_score(y_test, y_test_pred)\n",
    "precision_score(y_test, y_test_pred)\n",
    "f1_score(y_test, y_test_pred)\n",
    "accuracy_score(y_test, y_test_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51604e41",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f83d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(xticks_rotation=\"horizontal\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed1d04a5",
   "metadata": {},
   "source": [
    "#### Precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7fa9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_train)\n",
    "precision, recall, _ = precision_recall_curve(y_test_binary, y_pred_proba[:,1])\n",
    "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "disp.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7f7ce3f",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cfffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_prob[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "disp = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='roc_auc')\n",
    "disp.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e56a8ba5",
   "metadata": {},
   "source": [
    "#### K_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503eecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10,shuffle=True, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0508fbca",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_iter':[500, 1000], 'C':[0.01,0.1,10,100],'penalty':['l2','l1','elasticnet'],'solver':[\"saga\", \"liblinear\"]}\n",
    "lr = LogisticRegression()\n",
    "clf_ = GridSearchCV(lr, parameters, n_jobs=1)\n",
    "clf_.fit(X_train,y_train)\n",
    "\n",
    "clf_.score(X_test,y_test),clf_.score(X_train,y_train)\n",
    "clf_.best_score_\n",
    "clf_.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "grids_searchs = []\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=5,shuffle=True, random_state=0)\n",
    "\n",
    "linearsvc = {\"model_name\": \"LinearSVC\", \"model\": LinearSVC(), \"params\": {'penalty': [\"l1\", \"l2\"], 'C':[0,0.01,0.1,10,100], \"max_iter\": [1000,2000]}}\n",
    "\n",
    "svc = {\"model_name\": \"SVC\", \"model\": SVC(), \"params\": {'C':[0,0.01,0.1,10,100], 'gamma': [0.01,0.01,0.1,10,100], 'kernel': [\"rbf\", \"linear\"]}}\n",
    "\n",
    "lr = {\"model_name\": \"LogisticRegression\", \"model\": LogisticRegression(), \"params\": {'penalty': [\"l1\", \"l2\", \"elasticnet\"], 'C':[0,0.01,0.1,10,100], 'max_iter':[500, 1000], 'solver': ['newton-cg', 'lbfgs', 'liblinear']}}\n",
    "\n",
    "rf = {\"model_name\": \"RandomForestClassifier\", \"model\": RandomForestClassifier(), \"params\": {'criterion': [\"gini\", \"entropy\", \"log_loss\"], n_estimators: [10,100,1000], max_depth: [5,10], max_leaf_nodes:[0,0.01], min_samples_leaf:[0,0.01]} }\n",
    "\n",
    "for model in [linearsvc, svc, lr, rf]:\n",
    "    clf_ = GridSearchCV(model[\"model\"], model[\"params\"], scoring=[\"accuracy\", \"f1\"], refit = \"f1\", cv=kfold)\n",
    "    clf_.fit(X_train, y_train)\n",
    "    grids_searchs.append(clf_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71524626",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MeanShift, SpectralClustering,  AgglomerativeClustering, Birch, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aebe9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [KMeans(n_clusters=3), MeanShift(max_iter=10), SpectralClustering(),  AgglomerativeClustering(), Birch(), DBSCAN()]\n",
    "model.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c51fa742",
   "metadata": {},
   "source": [
    "#### silouhette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8678282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from sklearn.cluster import KMeans, MeanShift, SpectralClustering,  AgglomerativeClustering, Birch\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "results = []\n",
    "i=0\n",
    "k_tries = range(2, 10)\n",
    "for k in k_tries:\n",
    "    i+=1\n",
    "    plt.subplot(len(k_tries),1, i)\n",
    "    model = KMeans(n_clusters=k)\n",
    "    visualizer = SilhouetteVisualizer(model, colors='yellowbrick')\n",
    "\n",
    "    X, y = get_data('circles')\n",
    "    visualizer.fit(X)        # Fit the data to the visualizer\n",
    "    results.append((k, model.inertia_, visualizer.silhouette_score_))\n",
    "    print(results[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bbd3e12",
   "metadata": {},
   "source": [
    "#### elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "model = KMeans()\n",
    "#visualizer = KElbowVisualizer(model, k=(5, 10, 15, 20, 25, 30, 35, 40, 45, 50))\n",
    "visualizer = KElbowVisualizer(model, k=10)\n",
    "\n",
    "visualizer.fit(X)  # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b6b8555",
   "metadata": {},
   "source": [
    "#### dist√†ncies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c1930ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def sim_euclid(x, y):\n",
    "    p1 = np.sum([(a * a) for a in x])\n",
    "    p2 = np.sum([(b * b) for b in y])\n",
    "    p3 = -1 * np.sum([(2 * a*b) for (a, b) in zip(x, y)])\n",
    "    res = np.sqrt(np.sum(p1 + p2 + p3))\n",
    "    return res\n",
    "\n",
    "def sim_pearson(x, y):\n",
    "    res = x.corr(y)\n",
    "    return res\n",
    "\n",
    "def sim_cosine(x, y):\n",
    "    res = np.dot(x,y)/(norm(x)*norm(y))\n",
    "    return res\n",
    "\n",
    "def sim_mikowski(x, y):\n",
    "    res = distance.minkowski(x, y, 1)\n",
    "    return res\n",
    "\n",
    "def sim_manhattan(x, y):\n",
    "    np.abs(x[:,None] - c).sum(-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d92084b",
   "metadata": {},
   "source": [
    "#### calcular dist√†ncies respecte centroides kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c296a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans()\n",
    "model.fit(X)\n",
    "centroides = model.cluster_centers_\n",
    "\n",
    "distancies = sim_cosine(X, centroides)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "854456c5",
   "metadata": {},
   "source": [
    "### Recommender systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "115315ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lenskit.algorithms.popular'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlenskit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popular\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlenskit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bias\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlenskit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mitem_knn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ItemItem\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lenskit.algorithms.popular'"
     ]
    }
   ],
   "source": [
    "from lenskit.algorithms.popular import Popular\n",
    "from lenskit.algorithms.basic import Bias\n",
    "from lenskit.algorithms.item_knn import ItemItem\n",
    "from lenskit.algorithms.user_knn import UserUser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55058561",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_carlos_movie_ratings = pd.read_csv('carlos-movie-ratings.csv', delimiter=\";\").dropna().set_index(\"item\")\n",
    "num_recs = 10\n",
    "popular = Popular() \n",
    "popular = Recommender.adapt(popular)\n",
    "popular.fit(data.ratings)\n",
    "recs_popular = popular.recommend(-1, \n",
    "                                num_recs, \n",
    "                                ratings=pd_carlos_movie_ratings[\"ratings\"]) \n",
    "display(carlos_recs_popular.join(data.movies[['genres', 'title']], on='item'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dbbaa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:45:03</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:20:47</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:37:04</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-07-30 19:03:35</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-07-30 18:48:51</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:53:22</td>\n",
       "      <td>Split (2017)</td>\n",
       "      <td>Drama|Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 22:21:31</td>\n",
       "      <td>John Wick: Chapter Two (2017)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-08 19:50:47</td>\n",
       "      <td>Get Out (2017)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:19:12</td>\n",
       "      <td>Logan (2017)</td>\n",
       "      <td>Action|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-03 21:20:15</td>\n",
       "      <td>The Fate of the Furious (2017)</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user    item  rating           timestamp  \\\n",
       "0          1       1     4.0 2000-07-30 18:45:03   \n",
       "1          1       3     4.0 2000-07-30 18:20:47   \n",
       "2          1       6     4.0 2000-07-30 18:37:04   \n",
       "3          1      47     5.0 2000-07-30 19:03:35   \n",
       "4          1      50     5.0 2000-07-30 18:48:51   \n",
       "...      ...     ...     ...                 ...   \n",
       "100831   610  166534     4.0 2017-05-03 21:53:22   \n",
       "100832   610  168248     5.0 2017-05-03 22:21:31   \n",
       "100833   610  168250     5.0 2017-05-08 19:50:47   \n",
       "100834   610  168252     5.0 2017-05-03 21:19:12   \n",
       "100835   610  170875     3.0 2017-05-03 21:20:15   \n",
       "\n",
       "                                 title  \\\n",
       "0                     Toy Story (1995)   \n",
       "1              Grumpier Old Men (1995)   \n",
       "2                          Heat (1995)   \n",
       "3          Seven (a.k.a. Se7en) (1995)   \n",
       "4           Usual Suspects, The (1995)   \n",
       "...                                ...   \n",
       "100831                    Split (2017)   \n",
       "100832   John Wick: Chapter Two (2017)   \n",
       "100833                  Get Out (2017)   \n",
       "100834                    Logan (2017)   \n",
       "100835  The Fate of the Furious (2017)   \n",
       "\n",
       "                                             genres  \n",
       "0       Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                                    Comedy|Romance  \n",
       "2                             Action|Crime|Thriller  \n",
       "3                                  Mystery|Thriller  \n",
       "4                            Crime|Mystery|Thriller  \n",
       "...                                             ...  \n",
       "100831                        Drama|Horror|Thriller  \n",
       "100832                        Action|Crime|Thriller  \n",
       "100833                                       Horror  \n",
       "100834                                Action|Sci-Fi  \n",
       "100835                  Action|Crime|Drama|Thriller  \n",
       "\n",
       "[100836 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lenskit.datasets as ds\n",
    "import pandas as pd\n",
    "\n",
    "data = ds.MovieLens('ml-latest-small/')\n",
    "print(\"Successfully installed dataset.\")\n",
    "\n",
    "data.ratings.timestamp = pd.to_datetime(data.ratings.timestamp, unit='s')\n",
    "data.tags.timestamp = pd.to_datetime(data.tags.timestamp, unit='s')\n",
    "\n",
    "joined_data = data.ratings.join(data.movies[['title', 'genres']], on='item')\n",
    "display(joined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "xavier_movie_ratings = pd.read_csv('xavier-movie-ratings.csv', delimiter=\";\").set_index(\"item\")\n",
    "xavier_movie_ratings_not_na = xavier_movie_ratings.dropna()  \n",
    "xavier_movie_ratings_na = xavier_movie_ratings[xavier_movie_ratings[\"ratings\"].isna()]\n",
    "display(xavier_movie_ratings_not_na[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b997fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = Bias()\n",
    "bias.fit(data.ratings)\n",
    "f_df[\"bias\"] = bias.predict_for_user(-1, xavier_movie_ratings_na.index.values, xavier_movie_ratings_not_na.ratings)\n",
    "# (ùë¢,ùëñ)=ùúá+ùëèùëñ+ùëèùë¢\n",
    "\n",
    "item = ItemItem(nnbrs=None)\n",
    "item.fit(data.ratings)\n",
    "f_df[\"item\"] = item.predict_for_user(-1, xavier_movie_ratings_na.index.values, xavier_movie_ratings_not_na.ratings)\n",
    "# quan les nostres dades contenen m√©s usuaris que items.\n",
    "\n",
    "user = UserUser(nnbrs=None)\n",
    "user.fit(data.ratings)\n",
    "f_df[\"user\"] = user.predict_for_user(-1, xavier_movie_ratings_na.index.values, xavier_movie_ratings_not_na.ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1b04a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_films(DataFrame, User1, User2):\n",
    "    mv1 = DataFrame[DataFrame[\"user\"] == User1].loc[:,[\"item\", \"rating\"]]\n",
    "    mv2 = DataFrame[DataFrame[\"user\"] == User2].loc[:,[\"item\", \"rating\"]]\n",
    "    rep = mv1.merge(mv2, on=\"item\", how=\"inner\")\n",
    "    return rep, len(rep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36e03681",
   "metadata": {},
   "source": [
    "#### similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dbeb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(DataFrame, User1, User2, type_sim, min_common_items=1):\n",
    "    rep, len_rep = same_films(DataFrame, User1, User2)\n",
    "    \n",
    "    if len_rep==0:\n",
    "        return 0, 0, 0\n",
    "    if(len_rep<min_common_items):\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    x = rep[\"rating_x\"] \n",
    "    y = rep[\"rating_y\"] \n",
    "    \n",
    "    if type_sim == \"sim_euclid\":\n",
    "        res = sim_euclid(x,y)\n",
    "    elif type_sim == \"sim_pearson\":\n",
    "        res = sim_pearson(x,y)\n",
    "    if(np.isnan(res)):\n",
    "        return 0, 0, 0\n",
    "    return res, len_rep, y.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53d4aeed",
   "metadata": {},
   "source": [
    "#### predict sense alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39bcd2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_without_alpha(DataFrame, User1, item, type_sim, min_common_items=1):\n",
    "    p = DataFrame[(DataFrame[\"user\"] != User1) & (DataFrame[\"item\"] == item)]\n",
    "    reps = []\n",
    "    rats = []\n",
    "    for User2 in p[\"user\"].unique():\n",
    "        rat = p[p[\"user\"] == User2][\"rating\"].values\n",
    "        rep, len_rep, mer = sim(DataFrame, User1, User2, type_sim, min_common_items)\n",
    "        rats.append(rat)\n",
    "        reps.append(rep)\n",
    "    pred = 0\n",
    "    for simi, rating in zip(reps, rats):\n",
    "        pred += simi * rating\n",
    "    if sum(reps) == 0:\n",
    "        pred = DataFrame[\"rating\"].mean()\n",
    "    else:\n",
    "        pred = pred/sum(reps)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73784e48",
   "metadata": {},
   "source": [
    "#### predict with alpha propi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c4b59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_with_alpha(DataFrame, User1, item, type_sim, min_common_items=1):\n",
    "    p = DataFrame[(DataFrame[\"user\"] != User1) & (DataFrame[\"item\"] == item)]\n",
    "    len_reps = []\n",
    "    reps = []\n",
    "    rats = []\n",
    "    for User2 in p[\"user\"].unique():\n",
    "        rat = p[p[\"user\"] == User2][\"rating\"].values\n",
    "        rep, len_rep, y = sim(DataFrame, User1, User2, type_sim, min_common_items=1)\n",
    "        rats.append(rat)\n",
    "        reps.append(rep)\n",
    "        len_reps.append(len_rep)\n",
    "    pred=0\n",
    "    pred1 = 0\n",
    "    pred2 = 0\n",
    "    for simi, len_rep, rating in zip(reps, len_reps, rats):\n",
    "        pred += simi * rating\n",
    "        pred1 += (len_rep/sum(len_reps)+1) * simi * rating\n",
    "        pred2 += (len_rep/sum(len_reps) * len(len_reps)) * simi * rating\n",
    "    pred = pred/sum(reps)\n",
    "    pred1 = pred1/sum(reps)\n",
    "    pred2 = pred2/sum(reps)\n",
    "    return pred, pred1, pred2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0feea50",
   "metadata": {},
   "source": [
    "#### predict with alpha examen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4c36ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_with_alpha(DataFrame, User1, item, type_sim, min_common_items=1, k=1):\n",
    "    p = DataFrame[(DataFrame[\"user\"] != User1) & (DataFrame[\"item\"] == item)]\n",
    "    len_reps = []   # nombre de pel¬∑l√≠cules que el User1 ha vist en com√∫ amb cda un dels altres\n",
    "    simis = []      # dist√†ncia entre el User1 i cada un dels altres\n",
    "    rats = []       # rating de l'item a predir per cada un dels usuaris amb qui comparem\n",
    "    for User2 in p[\"user\"].unique():\n",
    "        rat = p[p[\"user\"] == User2][\"rating\"].values\n",
    "        simi, len_rep = sim(DataFrame, User1, User2, type_sim, min_common_items=1)\n",
    "        rats.append(rat)\n",
    "        simis.append(simi)\n",
    "        len_reps.append(len_rep)\n",
    "    pred=0\n",
    "    pred1 = 0\n",
    "    print(len_reps)\n",
    "    exp_len_reps = [np.exp(x) for x in len_reps]\n",
    "    print(exp_len_reps)\n",
    "    alphas = [exp_len_rep/sum(exp_len_reps) for exp_len_rep in exp_len_reps]\n",
    "    \n",
    "    elements = [(alpha, rat, simi) for alpha, rat, simi in sorted(zip(alphas, rats, simis), reverse=True)]\n",
    "    #k = min(len(elements)-1, k)\n",
    "    for e in elements[:int(len(elements)*k)+1]:\n",
    "        alpha = e[0]\n",
    "        simi = e[1]\n",
    "        rat = e[2]\n",
    "        pred += simi * rat\n",
    "        pred1 += alpha *simi * rat\n",
    "    pred = pred/sum(simis)\n",
    "    pred1 = pred1/sum(simis)\n",
    "    return pred, pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91842072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "joined_data = joined_data.sample(frac=1)\n",
    "joined_data\n",
    "joined_data_test = joined_data[:int(len(joined_data)*0.01)]\n",
    "ratings_gt = []\n",
    "ratings = []\n",
    "for i in range(len(joined_data_test)):\n",
    "    row = joined_data_test[i:i+1]\n",
    "    ratings_gt.append(row[\"rating\"])\n",
    "    ratings.append(pred_without_alpha(joined_data,row[\"user\"].values[0], row[\"item\"].values[0],\"sim_pearson\", 5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57e0fa39",
   "metadata": {},
   "source": [
    "#### experiment and crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb242495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.algorithms import Recommender, basic\n",
    "from lenskit import batch, topn, util\n",
    "import numpy as np\n",
    "\n",
    "def experiment(name, algo, train, test, n=20):\n",
    "    fittable = util.clone(algo)   # alguns metodes fallen al fet fit varis cops.. aixi funciona\n",
    "    \n",
    "    base = basic.Bias(damping=5)  # si el metode algo no pot predir alguna qualificaci√≥, agafa aquesta per defecte \n",
    "    fittable = basic.Fallback(fittable, base)\n",
    "\n",
    "    fittable = Recommender.adapt(fittable)   # de vegades no tots els algorismes tenen recomenadors (nom√©s predictors, aixi agafa el per defecte)\n",
    "\n",
    "    fittable.fit(train)\n",
    "    preds = batch.predict(fittable, test)\n",
    "    \n",
    "    users = test.user.unique()               # agafem els users de test per donar recomenacions\n",
    "    recs = batch.recommend(fittable, users, n)\n",
    "\n",
    "    # add the algorithm name for analyzability\n",
    "    recs['Algorithm'] = name\n",
    "    preds['Algorithm'] = name\n",
    "    return recs, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77418f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit import crossfold as xf\n",
    "import lenskit.util\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "def crossvalidar(ratings, models, splitting, metriques, n_partitions=5, n_recomenacions=10):\n",
    "    rnd = lenskit.util.rng(24)\n",
    "    \n",
    "    if splitting == \"row\":\n",
    "        folds = xf.partition_rows(ratings[['user', 'item', 'rating', 'timestamp']], n_partitions, rng_spec=rnd)       \n",
    "    elif splitting == \"user\":\n",
    "        n_test = xf.SampleFrac(0.2) # 20% of the ratings of the users from the test-fold\n",
    "        folds = xf.partition_users(ratings[['user', 'item', 'rating', 'timestamp']], n_partitions, n_test, rng_spec=rnd)\n",
    "    else:\n",
    "        raise(\"Splitting not known\")\n",
    "    \n",
    "    all_recs = []\n",
    "    all_preds = []\n",
    "    test_data = []\n",
    "    \n",
    "    print(\"CROSSVALIDATION\")\n",
    "    print(\"Data: {}\".format(ratings.shape))\n",
    "    print(\"Models: {}\".format(list(models.keys())))\n",
    "    print(\"Splitting: {}\".format(splitting))\n",
    "    print(\"Metrics: {}\".format([m.__name__ for m in metriques]))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    for i, (train, test) in enumerate(folds):\n",
    "        tqdm_inner_loop = tqdm(models, desc='[fold {} of {}]'.format(i+1, n_partitions))\n",
    "        for model_name in tqdm_inner_loop:\n",
    "            tqdm_inner_loop.set_postfix({\"model\": model_name, \"train\": train.shape[0], \"test\": test.shape[0]})\n",
    "            recs, preds = experiment(model_name, models[model_name], train, test, n=n_recomenacions)\n",
    "            all_recs.append(recs)\n",
    "            all_preds.append(preds)\n",
    "        test_data.append(test)\n",
    "\n",
    "    all_recs = pd.concat(all_recs, ignore_index=True)\n",
    "    all_preds = pd.concat(all_preds, ignore_index=True)\n",
    "    test_data = pd.concat(test_data, ignore_index=True)\n",
    "    \n",
    "    all_preds = all_preds.merge(test_data[[\"user\",\n",
    "                                           \"item\", \n",
    "                                           \"rating\"]].rename(columns={\"rating\":\"true_label\"}), \n",
    "                                on=[\"user\",\"item\"])\n",
    "        \n",
    "    results_predict = []\n",
    "    rla = topn.RecListAnalysis()\n",
    "    for m in metriques:\n",
    "        if \"topn\" in m.__module__:\n",
    "            rla.add_metric(m)\n",
    "\n",
    "    results = rla.compute(all_recs, test_data)\n",
    "    \n",
    "    for m in metriques:\n",
    "        if \"predict\" in m.__module__:\n",
    "            res = all_preds.groupby(['Algorithm','user']).apply(lambda df: m(df[\"prediction\"], df[\"true_label\"]))\n",
    "            results[m.__name__] = res\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.algorithms import item_knn, user_knn, als, basic, funksvd\n",
    "\n",
    "models = {\"bias\": basic.Bias(), \"item_knn\": item_knn.ItemItem(nnbrs=15), \"user_knn\": user_knn.UserUser(nnbrs=15), \"Implicit\": als.ImplicitMF(features=20), \"Biased\": als.BiasedMF(features=20), \"funksvd\": funksvd.FunkSVD(features=20)}\n",
    "\n",
    "from lenskit import topn\n",
    "from lenskit.metrics import predict\n",
    "\n",
    "metriques = [predict.mae, predict.rmse, topn.precision, topn.recall, topn.ndcg, topn.recip_rank]\n",
    "\n",
    "splitting = \"user\"\n",
    "\n",
    "splitting = \"user\"\n",
    "results = crossvalidar(data.ratings, models, splitting, metriques )\n",
    "results.groupby(\"Algorithm\").mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
